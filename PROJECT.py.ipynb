{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e701a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d378ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"C:\\Users\\BHAVYA\\Downloads\\project file\\archive (6)\\Training\"\n",
    "test = r\"C:\\Users\\BHAVYA\\Downloads\\project file\\archive (6)\\Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78e9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c539e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glioma', 'meningioma', 'notumor', 'pituitary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33bb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'glioma' contains 1321 images.\n",
      "Folder 'meningioma' contains 1339 images.\n",
      "Folder 'notumor' contains 1595 images.\n",
      "Folder 'pituitary' contains 1457 images.\n"
     ]
    }
   ],
   "source": [
    "for folder in fnames:\n",
    "    folder_path = os.path.join(root, folder)\n",
    "    num_images = len(os.listdir(folder_path))\n",
    "    print(f\"Folder '{folder}' contains {num_images} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01da89a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing glioma: 100%|███████████████████████████████████████████████████████████| 1321/1321 [00:27<00:00, 48.64it/s]\n",
      "Processing glioma_resized: 100%|███████████████████████████████████████████████████| 1321/1321 [00:19<00:00, 67.73it/s]\n",
      "Processing meningioma: 100%|███████████████████████████████████████████████████████| 1339/1339 [00:30<00:00, 44.42it/s]\n",
      "Processing notumor: 100%|██████████████████████████████████████████████████████████| 1595/1595 [00:31<00:00, 50.63it/s]\n",
      "Processing pituitary: 100%|████████████████████████████████████████████████████████| 1457/1457 [00:35<00:00, 41.23it/s]\n"
     ]
    }
   ],
   "source": [
    "## Model preprocessing\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "# Define constants for image size\n",
    "IMG_WIDTH, IMG_HEIGHT = 180, 180\n",
    "\n",
    "def preprocess_images_in_folders(root):\n",
    "    # Iterate over all folders in the root folder\n",
    "    for folder in os.listdir(root):\n",
    "        folder_path = os.path.join(root , folder)\n",
    "        \n",
    "        # Create a directory to store resized images if it doesn't exist\n",
    "        resized_folder_path = os.path.join(root , f\"{folder}_resized\")\n",
    "        os.makedirs(resized_folder_path, exist_ok=True)\n",
    "        \n",
    "        # Iterate over all images in the folder\n",
    "        for filename in tqdm(os.listdir(folder_path), desc=f\"Processing {folder}\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            resized_image_path = os.path.join(resized_folder_path, filename)\n",
    "            \n",
    "            # Preprocess and resize the image\n",
    "            preprocessed_img = preprocess_image(image_path)\n",
    "            \n",
    "            # Save the resized image\n",
    "            save_resized_image(preprocessed_img, resized_image_path)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load image\n",
    "    img = load_img(image_path, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    img = img.convert('L')  # 'L' mode converts to grayscale\n",
    "    \n",
    "    # Convert image to array\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    # Normalize pixel values to range [0, 1]\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "def save_resized_image(image_array, save_path):\n",
    "    # Convert the image array to uint8 data type\n",
    "    image_array = (image_array * 255).astype(np.uint8)\n",
    "    \n",
    "    # Reshape the image array to remove singleton dimensions\n",
    "    image_array = np.squeeze(image_array)\n",
    "    \n",
    "    # Create a PIL image\n",
    "    img = Image.fromarray(image_array)\n",
    "    \n",
    "    # Save the image\n",
    "    img.save(save_path)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "root_folder = r\"C:\\Users\\BHAVYA\\Downloads\\project file\\archive (6)\\Training\"\n",
    "preprocess_images_in_folders(root_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd045a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cff037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8356fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' ,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36053325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "398/398 [==============================] - 903s 2s/step - loss: -5753745178624.0000 - accuracy: 0.1041 - val_loss: -7707434680320.0000 - val_accuracy: 0.2328\n",
      "Epoch 2/10\n",
      "398/398 [==============================] - 714s 2s/step - loss: -531161155633152.0000 - accuracy: 0.1034 - val_loss: -314828149227520.0000 - val_accuracy: 0.2344\n",
      "Epoch 3/10\n",
      "398/398 [==============================] - 1136s 3s/step - loss: -5682107514880000.0000 - accuracy: 0.1038 - val_loss: -2327030997712896.0000 - val_accuracy: 0.2336\n",
      "Epoch 4/10\n",
      "207/398 [==============>...............] - ETA: 9:56 - loss: -18286057338437632.0000 - accuracy: 0.1029 "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2979e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
